## Классификация токсичности комментариев (учебный проект)

### Цель
Необходимо обучить модели классифицировать комментарии на позитивные и негативные на основе набора данных с разметкой о токсичности правок. <br>

### Требования:
метритка качества - F1>0,75<br>
<br>
### Выводы
После предварительной обработки комментариев (лемматизация, очистка от символов и стоп-слов) из представленного заказчиком набор данных с разметкой о токсичности правок, были обучены несколько моделей (LogisticRegressio, LogisticRegressio с перебором параметров через GridSearchCV, RandomForestClassifier с перебором параметров через Optuna, CatBoostClassifier, LGBMClassifier. Все модели проверены на адекватность.)<br>
Худший результат у случайного леса. Наилучшим образом смогли классифицировать комментарии на позитивные и негативные модель логистичекой регресси (со стандартными параметрами и перебором параметров) и CatBost. Метрика кчества этих мелей превысила необходимый порог в 0.75. Указанные модели показали хороший результат несмотря на большой объём данных.<br>
Отмечу что лучший результат по классификации комментариев показала модель CatBoost, но наименьший уровень переобученности у логистической регрессии с перебором параметров. Предположу, что наилучшей ммоделью для реализации данного проекта будет именно этот алгоритм.<br>

#### Проект завершен
